# COMPAS article

This [ProPublica article](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) demonstrates how investigative journalism can uncover bias in machine learning. The investigators built a similar model to those used in criminal sentencing, and in doing so uncovered that the COMPAS system skewed toward giving white defendants lower risk scores over black defendants.

If you'd like to explore further, the ProPublica team also released a follow-up article on their methods, called ["How We Analyzed the COMPAS Recidivism Algorithm."](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)

As you read through this investigation, keep the following questions in mind:

1) What steps could the company providing the algorithm have taken to increase fairness before this model went live? 

2) How many harmful black box models like COMPAS are likely in production across society today, and how we can fix them without needing to rely on months-long investigative journalism?  
