# Unfairness visualized

This [gender bias visualization tool](http://wordbias.umiacs.umd.edu/) built by a small team of hackathon participants shows just how biased our algorithms can be when given large datasets of real-life data.

As you explore this tool, looking through different word categories and the gendered words the algorithm surfaces, keep the following question in mind:

1) Imagine this same black box model was used in evaluating loan applications. How could the unfairness of words lead to different group outcomes? 
